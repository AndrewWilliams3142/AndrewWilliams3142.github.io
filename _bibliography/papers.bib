@article{zhao2017efficient,
  title={Efficient Multi-task Feature and Relationship Learning},
  author={Zhao, Han and <b>Stretcu, Otilia</b> and Negrinho, Renato and Smola, Alex and Gordon, Geoff},
  journal={In Neural Information Processing Systems Workshop on Learning With Limited Data},
  year={2017},
  pdf = {fetr/LLD_2017_paper_15.pdf},
  arxiv = {1702.04423},
  abbr       = {NIPS},
  abstract   = {{We propose a multi-convex framework for multitask learning that improves pre- dictions by learning relationships both between tasks and between features. Our framework is a generalization of related methods, that either learn task relationships, or feature relationships, but not both. We start with a hierarchical Bayesian model, and use the empirical Bayes method to transform the underlying inference problem into a multi-convex problem. To tackle the multi-convex optimization problem, we propose a block coordinate-wise minimization algorithm that has a closed form solution for each block subproblem. Naively these solutions would be expensive to compute, but by using the theory of doubly stochastic matrices, we are able to reduce the covariance learning subproblem to a minimum-weight perfect matching problem on a complete bipartite graph, and solve it analytically and efficiently. To solve the weight learning subproblem, we propose three different strategies that can be used no matter whether the instances are shared by multiple tasks or not. We demonstrate the efficiency of our method on both synthetic datasets and real-world datasets. Experiments show that the proposed optimization method is orders of magnitude faster than the previous projected gradient method, and our model is able to exploit the correlation structures among multiple tasks and features.}},
  poster = {fetr/poster_fetr_lld.pdf}
}


@inproceedings{fu2017brainzoom,
  title={BrainZoom: High Resolution Reconstruction from Multi-modal Brain Signals},
  author={Fu, Xiao<em class="star">*</em> and Huang, Kejun<em class="star">*</em> and <b>Stretcu, Otilia</b><em class="star">*</em> and Song, Hyun Ah<em class="star">*</em> and Papalexakis, Evangelos and Talukdar, Partha and Mitchell, Tom and Sidiropoulo, Nicholas and Faloutsos, Christos and Poczos, Barnabas},
  booktitle={Proceedings of the 2017 SIAM International Conference on Data Mining},
  pages={216--227},
  year={2017},
  organization={SIAM},
  abbr  = {SDM},
  pdf = {brainzoom/siam_paper.pdf},
  abstract = {{How close can we zoom in to observe brain activity? Our understanding is limited by the resolution of imaging modalities that exhibit good spatial but poor temporal resolution, or vice-versa. In this paper, we propose BRAINZOOM, an efficient imaging algorithm that cross-leverages multi-modal brain signals. BRAINZOOM (a) constructs high resolution brain images from multi-modal signals, (b) is scalable, and (c) is flexible in that it can easily incorporate various priors on the brain activities, such as sparsity, low rank, or smoothness. We carefully formulate the problem to tackle nonlinearity in the measurements (via variable splitting) and auto-scale between different modal signals, and judiciously design an inexact alternating optimization-based algorithmic framework to handle the problem with provable convergence guarantees. Our experiments using a popular realistic brain signal simulator to generate fMRI and MEG demonstrate that high spatio-temporal resolution brain imaging is possible from these two modalities. The experiments also suggest that smoothness seems to be the best prior, among several we tried.}}
}

@inproceedings{stretcu2015multiple,
  title={Multiple Frames Matching for Object Discovery in Video},
  author={<b>Stretcu, Otilia</b> and Leordeanu, Marius},
  booktitle={BMVC},
  volume={1},
  number={2},
  pages={3},
  year={2015},
  abbr  = {BMVC},
  pdf = {videoPCA/bmvc_videopca.pdf},
  website          = {https://sites.google.com/site/multipleframesmatching/},
  abstract      = {{Automatic discovery of foreground objects in video sequences is an important prob- lem in computer vision with applications to object tracking, video segmentation and clas- sification. We propose an efficient method for the discovery of object bounding boxes and the corresponding soft-segmentation masks across multiple video frames. We offer a graph matching formulation for bounding box selection and refinement using second and higher order terms. Our objective function takes into consideration local, frame-based information, as well as spatiotemporal and appearance consistency over multiple frames. First, we find an initial pool of candidate boxes using a novel and fast foreground esti- mation method in video, based on Principal Component Analysis. Then, we match the boxes across multiple frames using pairwise geometric and appearance terms. Finally, we refine their location and soft-segmentation using higher order potentials that estab- lish appearance regularity over multiple frames. We test our method on the large scale YouTube-Objects dataset and obtain state-of-the-art results on several object classes.}},
  presentation = {http://www.bmva.org/bmvc/2015/papers/paper186/index.html},
  code = {https://drive.google.com/drive/folders/0B7CshFGxfi_5aW13T2h5RDZ3djQ}
}